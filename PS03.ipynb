{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TH-lYYjqHwK6"
      },
      "source": [
        "Diego Toribio <br>\n",
        "Professor Fred Fontaine <br>\n",
        "EID-378 Finance <br>\n",
        "Problem Set III: MPT and Risk<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-08T20:27:26.622048Z",
          "iopub.status.busy": "2025-03-08T20:27:26.621706Z",
          "iopub.status.idle": "2025-03-08T20:27:31.584165Z",
          "shell.execute_reply": "2025-03-08T20:27:31.582547Z",
          "shell.execute_reply.started": "2025-03-08T20:27:26.622025Z"
        },
        "id": "NZyBwNjSHwK-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade yfinance pandas_datareader --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "EfDrEcVoKJ4L"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si79LMLnHwLA"
      },
      "source": [
        "In this assignment, you will be exploring:\n",
        "\n",
        "- Modern Portfolio Theory, including concepts such as the \\( \\beta \\) and Sharpe ratio.\n",
        "- V@R and CV@R risk measures, including their application to portfolio optimization (as an alternative to MPT)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQlHzWWCHwLA"
      },
      "source": [
        "## Section 1 - Preparing the Data\n",
        "\n",
        "1. Select **M = 5** stocks, and get the daily adjusted closing price over one year for them.\n",
        "\n",
        "2. Also get the S&P 500 index (daily) over the same year.\n",
        "\n",
        "3. We also want to determine a risk-free return to use for our portfolio models, based on 3-Month Treasury Bills. This will be explained separately.\n",
        "\n",
        "4. Compute the daily returns of the stocks and S&P 500 over the year. In order to have a return for each trading day, you should also grab the last trading day of the previous year. For example, for 2014, you should also grab Dec. 31, 2013, in order to compute the return for the first trading day (Jan. 2) of 2014. This idea is called 'pre-windowing.' It is fine if you determine the last trading day of the previous year \"manually\" (i.e., rather than writing systematic code that would \"always\" work).\n",
        "\n",
        "5. Subtract off the daily risk-free return from the daily returns of the stocks and S&P 500. Going forward, we are going to be working with these excess returns only (I will omit using the word \"excess\" but keep in mind, everything is excess!). For example, if we think in terms of the Markowitz bullet in the $ (\\sigma, \\mu) $ plane, the 'risk-free' point in the graph will actually be the origin (0,0). More generally, going forward in the analysis, you can link what is happening here back to the \"theory\" discussed in the lecture notes by acting as if the risk-free return is 0!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxXZj6r_HwLB"
      },
      "source": [
        "### 1.1 - Download Adjusted Close Prices\n",
        "\n",
        "We select five stocks and include the last trading day of the prior year for pre‑windowing, then use `yfinance` with `auto_adjust=True` to fetch their adjusted close series over a one‑year window.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-08T20:19:39.323779Z",
          "iopub.status.busy": "2025-03-08T20:19:39.323335Z",
          "iopub.status.idle": "2025-03-08T20:19:39.367212Z",
          "shell.execute_reply": "2025-03-08T20:19:39.366085Z",
          "shell.execute_reply.started": "2025-03-08T20:19:39.323741Z"
        },
        "id": "BJcXblseHwLC",
        "outputId": "552681ac-bf70-4973-9ccf-c1f9a81cd7a8",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1mTable 1\u001b[0m. Adjusted Close Prices for Selected Stocks (first five rows).\n",
            "+------------+------------+------------+------------+------------+------------+\n",
            "|    Date    |    AAPL    |    AMZN    |    GOOG    |    MSFT    |    TSLA    |\n",
            "+------------+------------+------------+------------+------------+------------+\n",
            "| 2021-12-31 | 174.516296 | 166.716995 | 143.997467 | 327.162018 | 352.260010 |\n",
            "| 2022-01-03 | 178.879929 | 170.404495 | 144.390594 | 325.634796 | 399.926666 |\n",
            "| 2022-01-04 | 176.609634 | 167.522003 | 143.735718 | 320.051117 | 383.196655 |\n",
            "| 2022-01-05 | 171.911850 | 164.356995 | 137.004593 | 307.765015 | 362.706665 |\n",
            "| 2022-01-06 | 169.042068 | 163.253998 | 136.902557 | 305.333069 | 354.899994 |\n",
            "+------------+------------+------------+------------+------------+------------+\n"
          ]
        }
      ],
      "source": [
        "# select 5 stocks and define the date range (including pre‑window day)\n",
        "tickers    = [\"AAPL\", \"MSFT\", \"GOOG\", \"AMZN\", \"TSLA\"]\n",
        "start_date = \"2021-12-31\"  # last trading day of prior year\n",
        "end_date   = \"2022-12-31\"  # one year later\n",
        "\n",
        "# download adjusted close prices\n",
        "stock_data = yf.download(\n",
        "    tickers,\n",
        "    start=start_date,\n",
        "    end=end_date,\n",
        "    progress=False,\n",
        "    auto_adjust=True\n",
        ")[\"Close\"]\n",
        "\n",
        "\n",
        "# prepare the first five rows for tabulation\n",
        "df_head = stock_data.head()\n",
        "rows = []\n",
        "for date, data in df_head.iterrows():\n",
        "    rows.append(\n",
        "        [date.strftime(\"%Y-%m-%d\")] +\n",
        "        [f\"{data[ticker]:.6f}\" for ticker in df_head.columns]\n",
        "    )\n",
        "\n",
        "print(\"\\n\\033[1mTable 1\\033[0m. Adjusted Close Prices for Selected Stocks (first five rows).\")\n",
        "print(tabulate(\n",
        "    rows,\n",
        "    headers=[\"Date\"] + list(df_head.columns),\n",
        "    tablefmt=\"pretty\"\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehHEr5sHHwLF"
      },
      "source": [
        "### 1.2 - Market Benchmark\n",
        "\n",
        "We fetch the S&P 500 “Adj Close” over the same pre‑windowed date range, reset its index into “Date” and “Adj Close” columns, then use `iterrows()` to build and display the first five rows in a neatly formatted table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-08T20:02:22.491329Z",
          "iopub.status.busy": "2025-03-08T20:02:22.490950Z",
          "iopub.status.idle": "2025-03-08T20:02:22.508710Z",
          "shell.execute_reply": "2025-03-08T20:02:22.507431Z",
          "shell.execute_reply.started": "2025-03-08T20:02:22.491296Z"
        },
        "id": "WXZH0MWzHwLF",
        "outputId": "adfe04f2-2a3c-4c10-9171-e7dd4f9dde50",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1mTable 2\u001b[0m. S&P 500 Adj Close (first five rows, 2 dp).\n",
            "+------------+-----------+\n",
            "|    Date    | Adj Close |\n",
            "+------------+-----------+\n",
            "| 2021-12-31 |  4766.18  |\n",
            "| 2022-01-03 |  4796.56  |\n",
            "| 2022-01-04 |  4793.54  |\n",
            "| 2022-01-05 |  4700.58  |\n",
            "| 2022-01-06 |  4696.05  |\n",
            "+------------+-----------+\n"
          ]
        }
      ],
      "source": [
        "# Download S&P 500 Adj Close\n",
        "sp500 = yf.download(\n",
        "    \"^GSPC\",\n",
        "    start=start_date,\n",
        "    end=end_date,\n",
        "    progress=False,\n",
        "    auto_adjust=False\n",
        ")[\"Adj Close\"]\n",
        "\n",
        "# Prepare DataFrame of first 5 rows\n",
        "df_sp500 = sp500.head(5).reset_index()\n",
        "df_sp500.columns = [\"Date\", \"Adj Close\"]\n",
        "\n",
        "# Build rows for tabulation via iterrows(), rounding to two decimal places\n",
        "rows = []\n",
        "for _, row in df_sp500.iterrows():\n",
        "    date_str = row[\"Date\"].strftime(\"%Y-%m-%d\")\n",
        "    price_str = f\"{row['Adj Close']:.2f}\"  # two decimal places\n",
        "    rows.append([date_str, price_str])\n",
        "\n",
        "# Print bolded table description and the table\n",
        "print(\"\\n\\033[1mTable 2\\033[0m. S&P 500 Adj Close (first five rows, 2 dp).\")\n",
        "print(tabulate(\n",
        "    rows,\n",
        "    headers=[\"Date\", \"Adj Close\"],\n",
        "    tablefmt=\"pretty\"\n",
        "))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48mxXAcQHwLF"
      },
      "source": [
        "### 1.3 – Risk‑Free Rate\n",
        "\n",
        "\n",
        "Convert the assumed $2\\%$ annual T‑Bill yield into a per‑trading‑day rate via  \n",
        "\n",
        "$$\n",
        "r_{\\mathrm{daily}} = (1.02)^{1/252} - 1,\n",
        "$$  \n",
        "\n",
        "and broadcast it across the full trading‑day index.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-08T20:03:03.613121Z",
          "iopub.status.busy": "2025-03-08T20:03:03.612780Z",
          "iopub.status.idle": "2025-03-08T20:03:03.621020Z",
          "shell.execute_reply": "2025-03-08T20:03:03.619865Z",
          "shell.execute_reply.started": "2025-03-08T20:03:03.613096Z"
        },
        "id": "JLxkeuLGHwLG",
        "outputId": "f04aa7b7-b4fb-4ce7-d004-2c288e57669e",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Daily risk‑free rate (per trading day): 7.858494e-05\n"
          ]
        }
      ],
      "source": [
        "# Assume a 2.0% annual T‑Bill yield\n",
        "annual_rf_rate = 0.02\n",
        "\n",
        "# Convert to per‑trading‑day rate (≈252 trading days)\n",
        "daily_rf_rate = (1 + annual_rf_rate)**(1/252) - 1\n",
        "\n",
        "# Create a series aligned with the stock_data index (for later subtraction)\n",
        "risk_free_daily = pd.Series(daily_rf_rate, index=stock_data.index)\n",
        "\n",
        "# Output the determined daily rate\n",
        "print(f\"Daily risk‑free rate (per trading day): {daily_rf_rate:.6e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6E3QNH6HwLG"
      },
      "source": [
        "### 1.4 – Daily Returns\n",
        "\n",
        "\n",
        "Use `.pct_change()` on the adjusted‑close series to compute  \n",
        "\n",
        "$$\n",
        "\\text{return}_t = \\frac{P_t - P_{t-1}}{P_{t-1}},\n",
        "$$  \n",
        "\n",
        "then drop the initial NaN so every target‑year date has a valid return.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-08T20:03:45.126664Z",
          "iopub.status.busy": "2025-03-08T20:03:45.126277Z",
          "iopub.status.idle": "2025-03-08T20:03:45.151062Z",
          "shell.execute_reply": "2025-03-08T20:03:45.149915Z",
          "shell.execute_reply.started": "2025-03-08T20:03:45.126632Z"
        },
        "id": "27ezYBt6HwLG",
        "outputId": "cccf6f03-a339-47ab-ef38-d410e27c05da",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1mTable 3\u001b[0m. Stock daily returns (first five rows).\n",
            "+------------+---------+---------+---------+---------+---------+\n",
            "|    Date    |  AAPL   |  AMZN   |  GOOG   |  MSFT   |  TSLA   |\n",
            "+------------+---------+---------+---------+---------+---------+\n",
            "| 2022-01-03 | 0.0250  | 0.0221  | 0.0027  | -0.0047 | 0.1353  |\n",
            "| 2022-01-04 | -0.0127 | -0.0169 | -0.0045 | -0.0171 | -0.0418 |\n",
            "| 2022-01-05 | -0.0266 | -0.0189 | -0.0468 | -0.0384 | -0.0535 |\n",
            "| 2022-01-06 | -0.0167 | -0.0067 | -0.0007 | -0.0079 | -0.0215 |\n",
            "| 2022-01-07 | 0.0010  | -0.0043 | -0.0040 | 0.0005  | -0.0354 |\n",
            "+------------+---------+---------+---------+---------+---------+\n",
            "\n",
            "\u001b[1mTable 4\u001b[0m. S&P 500 daily returns (first five rows).\n",
            "+------------+--------------+\n",
            "|    Date    | SP500 Return |\n",
            "+------------+--------------+\n",
            "| 2022-01-03 |    0.0064    |\n",
            "| 2022-01-04 |   -0.0006    |\n",
            "| 2022-01-05 |   -0.0194    |\n",
            "| 2022-01-06 |   -0.0010    |\n",
            "| 2022-01-07 |   -0.0041    |\n",
            "+------------+--------------+\n"
          ]
        }
      ],
      "source": [
        "# (4) Compute daily returns and drop the first NaN\n",
        "stock_returns  = stock_data.pct_change().dropna()\n",
        "sp500_returns  = sp500.pct_change().dropna()\n",
        "\n",
        "\n",
        "\n",
        "# Table 3: first five rows of stock returns\n",
        "print(\"\\n\\033[1mTable 3\\033[0m. Stock daily returns (first five rows).\")\n",
        "rows = []\n",
        "for date, row in stock_returns.head(5).iterrows():\n",
        "    rows.append([date.strftime(\"%Y-%m-%d\")] + [f\"{v:.4f}\" for v in row])\n",
        "print(tabulate(\n",
        "    rows,\n",
        "    headers=[\"Date\"] + list(stock_returns.columns),\n",
        "    tablefmt=\"pretty\"\n",
        "))\n",
        "\n",
        "# Table 4: first five rows of S&P 500 returns\n",
        "df_sp_ret = sp500_returns.head(5).reset_index()\n",
        "df_sp_ret.columns = [\"Date\", \"SP500 Return\"]\n",
        "\n",
        "rows = []\n",
        "for _, row in df_sp_ret.iterrows():\n",
        "    rows.append([row[\"Date\"].strftime(\"%Y-%m-%d\"), f\"{row['SP500 Return']:.4f}\"])\n",
        "\n",
        "print(\"\\n\\033[1mTable 4\\033[0m. S&P 500 daily returns (first five rows).\")\n",
        "print(tabulate(\n",
        "    rows,\n",
        "    headers=[\"Date\", \"SP500 Return\"],\n",
        "    tablefmt=\"pretty\"\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D2GI8mEHwLG"
      },
      "source": [
        "### 1.5 – Excess Returns\n",
        "\n",
        "Subtract the daily risk‑free series from each raw return series and drop any NaNs, yielding returns in excess of the risk‑free rate for all subsequent analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-08T20:04:25.300679Z",
          "iopub.status.busy": "2025-03-08T20:04:25.300267Z",
          "iopub.status.idle": "2025-03-08T20:04:25.321118Z",
          "shell.execute_reply": "2025-03-08T20:04:25.320012Z",
          "shell.execute_reply.started": "2025-03-08T20:04:25.300648Z"
        },
        "id": "m3cwnJHJHwLH",
        "outputId": "902e1e97-af25-47d8-9490-32459f8806a5",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1mTable 6a\u001b[0m. Excess stock returns (first 5 rows).\n",
            "+------------+---------+---------+---------+---------+---------+\n",
            "|    Date    |  AAPL   |  AMZN   |  GOOG   |  MSFT   |  TSLA   |\n",
            "+------------+---------+---------+---------+---------+---------+\n",
            "| 2022-01-03 | 0.0249  | 0.0220  | 0.0027  | -0.0047 | 0.1352  |\n",
            "| 2022-01-04 | -0.0128 | -0.0170 | -0.0046 | -0.0172 | -0.0419 |\n",
            "| 2022-01-05 | -0.0267 | -0.0190 | -0.0469 | -0.0385 | -0.0535 |\n",
            "| 2022-01-06 | -0.0168 | -0.0068 | -0.0008 | -0.0080 | -0.0216 |\n",
            "| 2022-01-07 | 0.0009  | -0.0044 | -0.0041 | 0.0004  | -0.0355 |\n",
            "+------------+---------+---------+---------+---------+---------+\n",
            "\n",
            "\u001b[1mTable 6b\u001b[0m. Excess S&P 500 returns (first 5 rows).\n",
            "+------------+---------------------+\n",
            "|    Date    | Excess SP500 Return |\n",
            "+------------+---------------------+\n",
            "| 2022-01-03 |       0.0063        |\n",
            "| 2022-01-04 |       -0.0007       |\n",
            "| 2022-01-05 |       -0.0195       |\n",
            "| 2022-01-06 |       -0.0010       |\n",
            "| 2022-01-07 |       -0.0041       |\n",
            "+------------+---------------------+\n"
          ]
        }
      ],
      "source": [
        "# (5) Compute excess returns and drop NaNs\n",
        "excess_stock_returns = stock_returns.sub(risk_free_daily, axis=0).dropna()\n",
        "excess_sp500_returns = sp500_returns.sub(risk_free_daily, axis=0).dropna()\n",
        "\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Table 6a: first five rows of excess stock returns\n",
        "print(\"\\n\\033[1mTable 6a\\033[0m. Excess stock returns (first 5 rows).\")\n",
        "rows = [\n",
        "    [date.strftime(\"%Y-%m-%d\")] + [f\"{v:.4f}\" for v in row]\n",
        "    for date, row in excess_stock_returns.head(5).iterrows()\n",
        "]\n",
        "print(tabulate(\n",
        "    rows,\n",
        "    headers=[\"Date\"] + list(excess_stock_returns.columns),\n",
        "    tablefmt=\"pretty\"\n",
        "))\n",
        "\n",
        "# Table 6b: first five rows of excess S&P 500 returns\n",
        "df_ex_sp = excess_sp500_returns.head(5).reset_index()\n",
        "df_ex_sp.columns = [\"Date\", \"Excess SP500 Return\"]\n",
        "\n",
        "print(\"\\n\\033[1mTable 6b\\033[0m. Excess S&P 500 returns (first 5 rows).\")\n",
        "rows = [\n",
        "    [row[\"Date\"].strftime(\"%Y-%m-%d\"), f\"{row['Excess SP500 Return']:.4f}\"]\n",
        "    for _, row in df_ex_sp.iterrows()\n",
        "]\n",
        "print(tabulate(\n",
        "    rows,\n",
        "    headers=[\"Date\", \"Excess SP500 Return\"],\n",
        "    tablefmt=\"pretty\"\n",
        "))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tru3gH47HwLH"
      },
      "source": [
        "## Section 2 - Data Analysis\n",
        "###  Modern Portfolio Theory\n",
        "\n",
        "#### Some Equations\n",
        "\n",
        "Let us write some equations (which apply in this form—with the risk-free return already subtracted off). Let $ C $ denote the covariance of the returns of the risky stocks (not the S&P 500), $ \\mathbf{m} $ the vector of their expected (excess) returns. Given a portfolio weight vector $ \\mathbf{w} $ (satisfying $\\sum w_k = 1$), the expected (excess) return and standard deviation for $ \\mathbf{w} $ is:\n",
        "\n",
        "$$\n",
        "\\mu(\\mathbf{w}) = \\mathbf{m}^T\\mathbf{w} \\\\\n",
        "\\sigma(\\mathbf{w}) = \\sqrt{\\mathbf{w}^T C \\mathbf{w}}\n",
        "$$\n",
        "\n",
        "Also let $ \\mathbf{1} $ denote the vector of all ones, as usual.  \n",
        "The weight vectors for the MVP and MP are:\n",
        "\n",
        "$$\n",
        "\\mathbf{w}_{MVP} = \\frac{1}{\\mathbf{1}^T C^{-1}\\mathbf{1}} C^{-1}\\mathbf{1} \\\\\n",
        "\\mathbf{w}_{MP} = \\frac{1}{\\mathbf{1}^T C^{-1}\\mathbf{m}} C^{-1}\\mathbf{m}\n",
        "$$\n",
        "\n",
        "From these you can compute the $\\mu, \\sigma$.\n",
        "\n",
        "If you have two portfolios (of the risky stocks only) with weight vectors $ \\mathbf{w}_1, \\mathbf{w}_2 $, the corresponding returns $ r_1, r_2 $ have covariance given by:\n",
        "\n",
        "$$\n",
        "cov(r_1, r_2) = \\mathbf{w}_1^T C \\mathbf{w}_2\n",
        "$$\n",
        "\n",
        "Otherwise, if you have the actual set of returns over a period of time, you can compute the covariance directly from the data. For example, you can do this to compute the covariance between one of your stocks and the S&P 500. If you store the covariances between each stock and the S&P 500 in a vector $ \\mathbf{q} $, then the covariance between a portfolio $ \\mathbf{w} $ of the stocks and the S&P 500 would be:\n",
        "\n",
        "$$\n",
        "cov(r_{\\mathbf{w}}, r_{S\\&P500}) = \\mathbf{q}^T\\mathbf{w}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "1. Using the data for the full year, we want to get the vector of expected returns and covariance matrix of the returns of the **M = 5** stocks, and the covariance between each stock and the S&P 500. Compute $ \\mathbf{w}_{MVP}, (\\sigma_{MVP}, \\mu_{MVP}) $ and $ \\mathbf{w}_{MP}, (\\sigma_{MP}, \\mu_{MP}) $ for the minimum variance and market portfolios, respectively. We will also need code that, given a weight vector for a portfolio from the stocks $ \\mathbf{w} $, we can compute the $ (\\sigma,\\mu) $ point; also that we can compute the covariance between two such portfolios; we also want the vector $ \\mathbf{q} $ of covariances with the S&P 500, and the ability to compute the covariance of a portfolio given by $ \\mathbf{w} $ with the S&P 500.\n",
        "\n",
        "2. Look at the MVP and MP weight vectors. Do they involve short-selling?\n",
        "\n",
        "3. Compute the Sharpe ratio and $ \\beta $ for each of the **M = 5** stocks, the S&P 500, and the MVP. Compute the covariance between the individual stocks, and the MVP and MP portfolios with the S&P 500. Display these results in a reasonable form, such as a table. Also provide a quick summary of which of these are positively or negatively correlated with the S&P 500.\n",
        "\n",
        "4. Generate **N = 100** random $ \\mathbf{w} $ vectors with **no short selling**; they have to satisfy the constraint that $\\sum_{k=1}^{M} w_k = 1$. To do this I suggest: (1) generate $ M $ independent numbers uniformly from 0 to 1, say $(x_1, x_2, \\dots, x_5)$, and then (2) set $ w_k = x_k / (\\sum x_k) $, i.e., normalize them to sum to 1. I suggest you store these vectors in an array (dataframe) as you will be using them again later!\n",
        "\n",
        "5. Compute the $ (\\sigma, \\mu) $ point for each of these vectors, and create a scatter plot of these $ (\\sigma, \\mu) $, also put in $ (\\sigma_{MVP}, \\mu_{MVP}) $, and $ (\\sigma_{MP}, \\mu_{MP}) $ and also compute and plot $ (\\sigma_{SP}, \\mu_{SP}) $ for the S&P 500. Also draw the CAL on your graph (remember, the \"risk-free\" point is now (0,0)).\n",
        "\n",
        "6. Find the median of the expected returns of those 100 portfolios that involve no short-selling, say $ \\mu_{med} $. Find the \"best\" portfolio (among those you created) whose return satisfies $ \\mu \\geq \\mu_{med} $, i.e., among all such, the $ \\sigma $ is minimum. Highlight that portfolio. We can consider that portfolio as an approximate solution to an optimization problem (find the portfolio with the no short selling constraint and achieves at least a prescribed expected return that minimizes risk *as measured by standard deviation*). For that optimal portfolio, compute its Sharpe ratio and $ \\beta $.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbitOshPHwLL"
      },
      "source": [
        "## Section 3 - V@R and CV@R\n",
        "\n",
        "1. Use the same dataset you collected for the previous problem. Consider the returns over one year for each of your stocks, plus S&P 500.\n",
        "\n",
        "  (a) Construct histograms for the returns with 50 bins, and plot them, for each of your stocks.\n",
        "\n",
        "  (b) Compute the V@R$_{1-\\alpha}$ and CV@R$_{1-\\alpha}$ for $\\alpha = 5\\%$ and $10\\%$, directly from the daily returns over the year, for each stock separately. **Note:** In practice, 5% and 1% are more common, but given the limited number of data points available, we are not likely to obtain reasonable results for 1%.\n",
        "\n",
        "2. Again, we are using the same dataset.\n",
        "\n",
        "  (a) Given the set of daily returns for the five stocks over one year, and a weight vector $ \\mathbf{w} $ for a portfolio, write code to compute the V@R and CV@R for prescribed $\\alpha$.\n",
        "\n",
        "  (b) Compute the V@R$_{1-\\alpha}$ and CV@R$_{1-\\alpha}$ for the MVP, MP, and S&P 500.\n",
        "\n",
        "  (c) Use the **SAME** set of 100 random weight vectors with no short selling as you used from the MPT section of this assignment. You already have the expected returns. Now compute the CV@R$_{1-\\alpha}$ for $\\alpha = 10\\%$ and $\\alpha = 5\\%$ for each of them.\n",
        "\n",
        "  (d) Obtain a scatter plot with axes $(CV@R_{1-\\alpha}, \\mu)$ for your 100 weight vectors, plus the MVP, MP, S&P 500, and each of your individual stocks, for $\\alpha = 10\\%$. Obtain a separate scatter plot for $\\alpha = 5\\%$.\n",
        "\n",
        "\n",
        "  (f) You now have three (estimated) \"optimal\" portfolios obtained under 3 different risk measures: standard deviation, and CV@R at two levels. Summarize in a table for these 3 the following: the expected return, Sharpe ratio, $\\beta$, standard deviation, and both CV@R values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyaxsDrXHwLM",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJIjVIktHwLM"
      },
      "source": [
        "## Section 4 - Comment\n",
        "\n",
        "You obtained three scatter plots corresponding to three criteria for optimization. The \"upper bound\" on your scatter plots represent, essentially, \"efficient frontiers\" with respect to these risk measures (i.e., for a given return, the risk measure is minimized). Recall that for the standard deviation, this \"upper bound\" is a hyperbola, and specifically is a concave curve. Do your results appear to be concave in each of the other cases?\n",
        "\n",
        "Here, I asked you to create 100 random portfolios. You may want to try more, if your computer can handle it. If you work with 1000, do your scatter plots and final \"optimal\" choices change considerably?\n",
        "\n",
        "One more comment: in many cases, the V@R and CV@R are computed using the formulas that apply for the case of a Gaussian model. This may be useful in achieving a more systematic approach to solving the optimization problem, rather than the crude \"random search\" given here, but again presumes the Gaussian model is accurate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZ06lsMBHwLM",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a__Tfc0cHwLN"
      },
      "source": [
        "## Section 6 - Some Extra Things to Try [Optional]\n",
        "\n",
        "As mentioned above, a common approach to V@R/CV@R is to presume a Gaussian distribution. Two questions:\n",
        "\n",
        "- Is the data actually Gaussian? Select one or more suitable statistical tests to assess whether the data you are looking at is Gaussian.\n",
        "\n",
        "- Repeat your CV@R portfolio optimization approach using the formulas that arise under the Gaussian assumption, rather than the one based on quantile measurement. Is there an appreciable difference in results?\n",
        "\n",
        "- I seem to be implying that CV@R with the Gaussian model is not as accurate as that based on a quantile approach. However, considering the experiment above, there is a flaw in directly measuring the quantiles and using that to obtain the CV@R. In fact, it may very well be that the model-based approach to CV@R could give superior results! **WHY?**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30918,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
